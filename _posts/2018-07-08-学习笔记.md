---
layout:     post
title:      "学习笔记"
subtitle:   "20180708学习笔记"
date:       2018-07-08 12:00:00
author:     "LamFZ"
header-img: "img/post-bg-rwd.jpg"
catalog: true
tags:
    - 生活
---

# 学习报告
## 论文一 基于社交网络信息爬虫的设计与实现研究
### 获取社交网络信息过程终中的问题
* 传统爬虫无法有限获取信息
 * 内容多样性以及网页异步渲染
* 关系数据库的存储问题
 * 除文本外，用户信息，评论等信息降低了不同内容之间的关联性
* 信息抓取过滤问题
 * 用户量大，信息量大，信息噪声多

### 设计与实现
* 爬虫模块组成
 * 信息抓取模块 -> 抓取页面信息
 * 信息存储模块
 * 信息检索模块

### 各个模块的设计与实现

* 信息抓取模块
 * AJAX解析页面
 * 当页面发生变化时，对应的URL会发生变化(静态页面)
 * 通过DOM熟结构动态变化（动态页面）
* 信息存储模块
 * 为了保证页面信息的细致性和全面性，一般使用非关系型数据库
 * 一般使用 Sharding+Replica Set 的方法
* 信息检索模块
 * 非关系数据库
 * 时间维度
 * 用户维度
 * 页面维度

### 小结
社交网络平台因为其开放性，因而在数据库手段和网页爬取的方法上与传统爬虫区别。主要在数据库要使用非关系数据库，使用爬取动态网页的处理方法以及对于反爬网站的处理上。

## 论文二 网络爬虫针对反爬网站的爬取策略研究
### 爬虫的基本组成
* 控制器>>>分配与调度线程
* 解析器>>>对下载的网页的内容进行处理
* 资源库>>>保存下载网页资源，创建索引

### 爬虫的搜索策略
* 广度优先>>>从根节点开始，完成当前层次的搜索后才跳到下一层。初始URL在一定距离内，网页具有主题相关性的概率很大
* 深度优先>>>从根节点开始，一个链接一个链接跟踪下去，处理完线路后到下个起始页。
* 最佳优先搜索>>>计算URL描述文本与目标网页的相似度与相关性，根据阈值选出有效URL进行抓取
* 反向链接数>>>方向链接数表示的是一个网页的内容收到其他人的推荐程度。判断重要性，决定抓取先后顺序。

### 应对网站反爬虫机制

一般网站会
* 识别User-Agent信息来识别爬虫
* 通过Filter过滤
* 网站流量统计系统
* 日志分析

解决方法
* 降低访问请求频率
* 设置代理服务器
* 伪装用户代理（使用知名的浏览器）
* 自动登录>>>使用badboy录制POST请求中的所有参数，然后进行模拟

## 论文三 基于网络爬虫的导航深度服务信息自动采集
### 深度服务信息定义以结构
根据信息关注点以及网络信息，根据POI，将网络信息与POI进行匹配
### 深度服务信息自动采集
* 根据POI信息生成字段为关键字
* 使用爬虫获取主站下的服务地点URL，提取服务信息
* 针对获取的信息，计算相似度，，使用算方分别编辑距离和最大公共子序列

###爬虫设计
* 采用广度优先策略，
* 参考基于相似聚类算法方垂直搜索引擎中正则表达式的应用 设计链接过滤器
* 使用DOM，解析网页的文本内容
* 基于目标网页名称，地址相似度的计算方法
 * 编辑距离计算名称相似度>>>从源自读到目标字符的最少插入，删除和替换的数目
 * 最大公共子序列计算地址相似度>>>将两个字符串分别删去多个字符，但不改变顺序后得到的长度最长的相同字符序列


小结
> 在之前的爬虫项目中，对于爬虫的细致的框架以及爬虫的模块的设计没有很好的理解。
> 还有在数据的关联性以及对网页的结构没有完整的了解
> 但是在第二篇论文中，在对于一些大型购物网站，如京东，如果访问时间间隔一定，也是会被ban的，可以使用随机时间访问页面。
> 而且在广度优先爬取中，按页码顺序访问页面也会被ban，因此可以将等待爬取URL中的顺序进行打乱，再进行爬取。
> 第一篇论文中少提了很多在社交网络中爬取信息遇到的问题，比如账号，ip，账号信息完整度（手机注册存活率高）等等
> 第三篇论文是基于地位位置信息的，广度优先的爬虫，并做了数据清晰以及处理。

